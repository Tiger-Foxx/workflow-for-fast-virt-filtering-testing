#!/usr/bin/env python3
"""
Script d'analyse ULTIME des r√©sultats de tests Snort 3
Version ULTIMATE EDITION - Histogrammes comparatifs avanc√©s

Auteur: Assistant IA pour theTigerFox
Date: 2025-07-28
Version: ULTIMATE 3.0 - Full Histogram Edition

Ce script g√©n√®re des histogrammes comparatifs d√©taill√©s pour analyser 
VRAIMENT les performances de Snort 3 √† diff√©rents d√©bits.

D√©pendances:
- pandas
- matplotlib
- numpy
- ace_tools (optionnel)

Usage:
    python3 analyze_snort_results_ultimate.py /chemin/vers/results
    python3 analyze_snort_results_ultimate.py .  # pour le r√©pertoire courant
"""

import os
import sys
import re
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import warnings
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime

# Gestion optionnelle d'ace_tools
try:
    import ace_tools
    ACE_TOOLS_AVAILABLE = True
except ImportError:
    ACE_TOOLS_AVAILABLE = False
    warnings.warn("ace_tools non disponible, le DataFrame sera affich√© avec print()")

class SnortUltimateAnalyzer:
    """
    Analyseur ULTIME des r√©sultats Snort 3 avec histogrammes comparatifs avanc√©s
    
    Cette classe g√©n√®re des graphiques histogramme vraiment utiles pour comparer
    les performances √† diff√©rents d√©bits avec des m√©triques pertinentes.
    """
    
    def __init__(self, results_dir: str):
        self.results_dir = Path(results_dir)
        self.figures_dir = self.results_dir / "figures"
        self.data = []
        
        # Cr√©er le dossier figures s'il n'existe pas
        self.figures_dir.mkdir(exist_ok=True)
        
        # Configuration matplotlib pour des graphiques √©poustouflants
        plt.style.use('default')
        plt.rcParams['figure.facecolor'] = 'white'
        plt.rcParams['axes.facecolor'] = 'white'
        plt.rcParams['font.size'] = 11
        plt.rcParams['axes.titlesize'] = 14
        plt.rcParams['axes.labelsize'] = 12
        plt.rcParams['legend.fontsize'] = 11
        
        print("üöÄ Initialisation de l'analyseur ULTIME Snort 3")
    
    def extract_pps_from_dirname(self, dirname: str) -> Optional[int]:
        """Extrait la valeur pps du nom de dossier (ex: '1000pps' -> 1000)"""
        match = re.search(r'(\d+)pps', dirname.lower())
        return int(match.group(1)) if match else None
    
    def parse_metrics_file(self, filepath: Path) -> Dict[str, Any]:
        """
        Parse le fichier metrics.txt avec extraction pr√©cise des valeurs
        
        Format attendu:
        perf_monitor.packets_total:    69545
        latency.total_usecs_sum:      0
        latency.max_usecs:            0
        latency.avg_usecs_per_pkt:    0.00
        cpu.user_usec:                974415
        cpu.sys_usec:                 1270970
        cpu.total_usec:               2245385
        runtime_sec:                  303
        debit_avg_pps:                229.52
        """
        metrics = {}
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Patterns pr√©cis pour extraction
            patterns = {
                'packets_total': r'perf_monitor\.packets_total:\s*(\d+)',
                'latency_total_usecs_sum': r'latency\.total_usecs_sum:\s*(\d+)',
                'latency_max_usecs': r'latency\.max_usecs:\s*(\d+)',
                'latency_avg_usecs_per_pkt': r'latency\.avg_usecs_per_pkt:\s*([\d.]+)',
                'cpu_user_usec': r'cpu\.user_usec:\s*(\d+)',
                'cpu_sys_usec': r'cpu\.sys_usec:\s*(\d+)',
                'cpu_total_usec': r'cpu\.total_usec:\s*(\d+)',
                'runtime_sec': r'runtime_sec:\s*(\d+)',
                'debit_avg_pps': r'debit_avg_pps:\s*([\d.]+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    value = match.group(1)
                    metrics[key] = float(value) if '.' in value else int(value)
                else:
                    print(f"‚ö†Ô∏è  Valeur '{key}' non trouv√©e dans {filepath}")
                    metrics[key] = 0
                    
        except Exception as e:
            print(f"‚ùå Erreur lors de la lecture de {filepath}: {e}")
            
        return metrics
    
    def parse_console_output(self, filepath: Path) -> Dict[str, Any]:
        """
        Parse CORRECTEMENT la sortie console (sortie.txt) selon le format r√©el
        
        Le fichier contient des sections s√©par√©es par des lignes de tirets.
        Structure r√©elle:
        --------------------------------------------------
        codec
                            total: 69882        (100.000%)
                            other: 30           (  0.043%)
        ...
        --------------------------------------------------
        Module Statistics
        --------------------------------------------------
        detection
                         analyzed: 69882
        --------------------------------------------------
        """
        console_data = {}
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # === EXTRACTION SECTION CODEC ===
            # Recherche de la section codec entre les s√©parateurs
            codec_match = re.search(r'codec\s*\n(.*?)(?:\n-{10,})', content, re.DOTALL)
            if codec_match:
                codec_data = {}
                codec_section = codec_match.group(1)
                
                # Extraction de chaque protocole avec pattern pr√©cis
                # Format: "                    arp: 68425        ( 97.915%)"
                protocol_lines = re.findall(r'\s*(\w+):\s*(\d+)\s*\(.*?\)', codec_section)
                
                for protocol, count in protocol_lines:
                    codec_data[protocol] = int(count)
                    
                console_data['codec'] = codec_data
                print(f"‚úÖ Codec: {len(codec_data)} protocoles extraits: {list(codec_data.keys())}")
            else:
                print("‚ö†Ô∏è  Section codec non trouv√©e")
                console_data['codec'] = {}
            
            # === EXTRACTION MODULES ===
            # Recherche dans la section "Module Statistics"
            module_section_match = re.search(r'Module Statistics\s*\n-+\s*(.*?)(?:\n[A-Z].*Statistics|\nSummary Statistics|$)', 
                                           content, re.DOTALL)
            
            if module_section_match:
                module_section = module_section_match.group(1)
                
                # Module Detection
                detection_match = re.search(r'detection\s*\n\s*analyzed:\s*(\d+)', module_section)
                console_data['detection_analyzed'] = int(detection_match.group(1)) if detection_match else 0
                
                # Module perf_monitor
                perf_monitor_match = re.search(r'perf_monitor\s*\n\s*packets:\s*(\d+)', module_section)
                console_data['perf_monitor_packets'] = int(perf_monitor_match.group(1)) if perf_monitor_match else 0
                
                # Module port_scan
                port_scan_packets_match = re.search(r'port_scan\s*\n\s*packets:\s*(\d+)', module_section)
                port_scan_trackers_match = re.search(r'port_scan\s*\n.*?trackers:\s*(\d+)', module_section, re.DOTALL)
                console_data['port_scan_packets'] = int(port_scan_packets_match.group(1)) if port_scan_packets_match else 0
                console_data['port_scan_trackers'] = int(port_scan_trackers_match.group(1)) if port_scan_trackers_match else 0
                
                # Module stream
                stream_flows_match = re.search(r'stream\s*\n\s*flows:\s*(\d+)', module_section)
                stream_prunes_match = re.search(r'stream\s*\n.*?total_prunes:\s*(\d+)', module_section, re.DOTALL)
                stream_idle_match = re.search(r'stream\s*\n.*?idle_prunes:\s*(\d+)', module_section, re.DOTALL)
                
                console_data['stream_flows'] = int(stream_flows_match.group(1)) if stream_flows_match else 0
                console_data['stream_total_prunes'] = int(stream_prunes_match.group(1)) if stream_prunes_match else 0
                console_data['stream_idle_prunes'] = int(stream_idle_match.group(1)) if stream_idle_match else 0
                
                # Module arp_spoof
                arp_spoof_match = re.search(r'arp_spoof\s*\n\s*packets:\s*(\d+)', module_section)
                console_data['arp_spoof_packets'] = int(arp_spoof_match.group(1)) if arp_spoof_match else 0
                
                # Module binder
                binder_raw_match = re.search(r'binder\s*\n\s*raw_packets:\s*(\d+)', module_section)
                binder_flows_match = re.search(r'binder\s*\n.*?new_flows:\s*(\d+)', module_section, re.DOTALL)
                binder_inspects_match = re.search(r'binder\s*\n.*?inspects:\s*(\d+)', module_section, re.DOTALL)
                
                console_data['binder_raw_packets'] = int(binder_raw_match.group(1)) if binder_raw_match else 0
                console_data['binder_new_flows'] = int(binder_flows_match.group(1)) if binder_flows_match else 0
                console_data['binder_inspects'] = int(binder_inspects_match.group(1)) if binder_inspects_match else 0
                
                print(f"‚úÖ Modules extraits: detection={console_data['detection_analyzed']}, "
                      f"port_scan={console_data['port_scan_packets']}, stream={console_data['stream_flows']}")
            else:
                print("‚ö†Ô∏è  Section Module Statistics non trouv√©e")
                for key in ['detection_analyzed', 'perf_monitor_packets', 'port_scan_packets', 
                           'port_scan_trackers', 'stream_flows', 'stream_total_prunes', 
                           'stream_idle_prunes', 'arp_spoof_packets', 'binder_raw_packets', 
                           'binder_new_flows', 'binder_inspects']:
                    console_data[key] = 0
                    
        except Exception as e:
            print(f"‚ùå Erreur lors de la lecture de {filepath}: {e}")
            
        return console_data
    
    def calculate_ultimate_metrics(self, data_row: Dict[str, Any]) -> Dict[str, float]:
        """
        Calcule TOUTES les m√©triques comparatives utiles
        
        Ces m√©triques permettront de cr√©er des histogrammes comparatifs significatifs
        """
        metrics = {}
        
        # === M√âTRIQUES DE BASE ===
        # Efficacit√© de d√©bit (%)
        if data_row['rate_pps'] > 0:
            metrics['throughput_efficiency_pct'] = (data_row['debit_avg_pps'] / data_row['rate_pps']) * 100
            metrics['packet_loss_pct'] = 100 - metrics['throughput_efficiency_pct']
        else:
            metrics['throughput_efficiency_pct'] = 0
            metrics['packet_loss_pct'] = 100
        
        # === M√âTRIQUES CPU AVANC√âES ===
        metrics['cpu_total_sec'] = (data_row['cpu_user_usec'] + data_row['cpu_sys_usec']) / 1_000_000
        metrics['cpu_user_sec'] = data_row['cpu_user_usec'] / 1_000_000
        metrics['cpu_sys_sec'] = data_row['cpu_sys_usec'] / 1_000_000
        
        # Charge CPU r√©elle (% du temps total)
        if data_row['runtime_sec'] > 0:
            metrics['cpu_load_pct'] = (metrics['cpu_total_sec'] / data_row['runtime_sec']) * 100
            metrics['cpu_user_load_pct'] = (metrics['cpu_user_sec'] / data_row['runtime_sec']) * 100
            metrics['cpu_sys_load_pct'] = (metrics['cpu_sys_sec'] / data_row['runtime_sec']) * 100
        else:
            metrics['cpu_load_pct'] = 0
            metrics['cpu_user_load_pct'] = 0
            metrics['cpu_sys_load_pct'] = 0
        
        # === RATIOS CRITIQUES POUR HISTOGRAMMES ===
        # Paquets par seconde de CPU
        if metrics['cpu_total_sec'] > 0:
            metrics['packets_per_cpu_sec'] = data_row['packets_total'] / metrics['cpu_total_sec']
        else:
            metrics['packets_per_cpu_sec'] = 0
        
        # Paquets par seconde de runtime
        if data_row['runtime_sec'] > 0:
            metrics['packets_per_runtime_sec'] = data_row['packets_total'] / data_row['runtime_sec']
        else:
            metrics['packets_per_runtime_sec'] = 0
        
        # Ratio efficacit√© CPU/Runtime
        if metrics['packets_per_runtime_sec'] > 0:
            metrics['cpu_efficiency_ratio'] = metrics['packets_per_cpu_sec'] / metrics['packets_per_runtime_sec']
        else:
            metrics['cpu_efficiency_ratio'] = 0
        
        # Temps CPU par paquet (¬µs/paquet)
        if data_row['packets_total'] > 0:
            metrics['cpu_time_per_packet_usec'] = (data_row['cpu_user_usec'] + data_row['cpu_sys_usec']) / data_row['packets_total']
            metrics['cpu_user_time_per_packet_usec'] = data_row['cpu_user_usec'] / data_row['packets_total']
            metrics['cpu_sys_time_per_packet_usec'] = data_row['cpu_sys_usec'] / data_row['packets_total']
        else:
            metrics['cpu_time_per_packet_usec'] = 0
            metrics['cpu_user_time_per_packet_usec'] = 0
            metrics['cpu_sys_time_per_packet_usec'] = 0
        
        # Ratio User/System CPU
        if data_row['cpu_sys_usec'] > 0:
            metrics['cpu_user_sys_ratio'] = data_row['cpu_user_usec'] / data_row['cpu_sys_usec']
        else:
            metrics['cpu_user_sys_ratio'] = 0
        
        # === M√âTRIQUES DE MODULES ===
        # Efficacit√© de d√©tection
        if data_row['rate_pps'] > 0:
            metrics['detection_efficiency_pct'] = (data_row['detection_analyzed'] / (data_row['rate_pps'] * data_row['runtime_sec'])) * 100
        else:
            metrics['detection_efficiency_pct'] = 0
        
        # Paquets d√©tect√©s par seconde
        if data_row['runtime_sec'] > 0:
            metrics['detection_pps'] = data_row['detection_analyzed'] / data_row['runtime_sec']
        else:
            metrics['detection_pps'] = 0
        
        # Flux par seconde
        if data_row['runtime_sec'] > 0:
            metrics['flows_per_sec'] = data_row['stream_flows'] / data_row['runtime_sec']
        else:
            metrics['flows_per_sec'] = 0
        
        # Paquets par flux
        if data_row['stream_flows'] > 0:
            metrics['packets_per_flow'] = data_row['detection_analyzed'] / data_row['stream_flows']
        else:
            metrics['packets_per_flow'] = 0
        
        return metrics
    
    def collect_data(self):
        """Collecte les donn√©es avec parsing correct des fichiers"""
        print(f"üîç Recherche des dossiers de r√©sultats dans {self.results_dir}")
        
        pps_dirs = [d for d in self.results_dir.iterdir() 
                   if d.is_dir() and d.name.lower().endswith('pps')]
        
        if not pps_dirs:
            print("‚ùå Aucun dossier se terminant par 'pps' trouv√©")
            return
        
        print(f"üìÅ Dossiers trouv√©s: {[d.name for d in pps_dirs]}")
        
        for pps_dir in sorted(pps_dirs, key=lambda x: self.extract_pps_from_dirname(x.name) or 0):
            rate_pps = self.extract_pps_from_dirname(pps_dir.name)
            if rate_pps is None:
                print(f"‚ö†Ô∏è  Impossible d'extraire le d√©bit de {pps_dir.name}")
                continue
                
            print(f"\nüìä Analyse du dossier {pps_dir.name} (d√©bit: {rate_pps} pps)")
            
            metrics_file = pps_dir / "metrics.txt"
            sortie_file = pps_dir / "sortie.txt"
            
            # V√©rification de l'existence des fichiers
            if not metrics_file.exists():
                print(f"‚ùå Fichier manquant: {metrics_file}")
                continue
            if not sortie_file.exists():
                print(f"‚ùå Fichier manquant: {sortie_file}")
                continue
            
            # Extraction des donn√©es
            metrics = self.parse_metrics_file(metrics_file)
            console = self.parse_console_output(sortie_file)
            
            # Compilation des donn√©es de base
            row_data = {
                'rate_pps': rate_pps,
                'packets_total': metrics.get('packets_total', 0),
                'runtime_sec': metrics.get('runtime_sec', 0),
                'debit_avg_pps': metrics.get('debit_avg_pps', 0),
                'latency_avg_usecs': metrics.get('latency_avg_usecs_per_pkt', 0),
                'latency_max_usecs': metrics.get('latency_max_usecs', 0),
                'cpu_user_usec': metrics.get('cpu_user_usec', 0),
                'cpu_sys_usec': metrics.get('cpu_sys_usec', 0),
                'detection_analyzed': console.get('detection_analyzed', 0),
                'perf_monitor_packets': console.get('perf_monitor_packets', 0),
                'port_scan_packets': console.get('port_scan_packets', 0),
                'port_scan_trackers': console.get('port_scan_trackers', 0),
                'stream_flows': console.get('stream_flows', 0),
                'stream_total_prunes': console.get('stream_total_prunes', 0),
                'stream_idle_prunes': console.get('stream_idle_prunes', 0),
                'arp_spoof_packets': console.get('arp_spoof_packets', 0),
                'binder_raw_packets': console.get('binder_raw_packets', 0),
                'binder_new_flows': console.get('binder_new_flows', 0),
                'binder_inspects': console.get('binder_inspects', 0),
                'codec_data': console.get('codec', {})
            }
            
            # Calcul des m√©triques avanc√©es
            advanced_metrics = self.calculate_ultimate_metrics(row_data)
            row_data.update(advanced_metrics)
            
            self.data.append(row_data)
            print(f"‚úÖ Donn√©es extraites pour {rate_pps} pps - Detection: {row_data['detection_analyzed']} paquets")
    
    def create_histogram_debit_comparison(self):
        """
        HISTOGRAMME 1: Comparaison des d√©bits mesur√©s vs inject√©s
        
        Histogramme c√¥te √† c√¥te montrant clairement l'√©cart entre
        le d√©bit inject√© et le d√©bit r√©ellement mesur√© par Snort.
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
        
        rates = [d['rate_pps'] for d in self.data]
        measured_rates = [d['debit_avg_pps'] for d in self.data]
        efficiencies = [d['throughput_efficiency_pct'] for d in self.data]
        
        # Graphique 1: Histogramme comparatif d√©bit inject√© vs mesur√©
        x = np.arange(len(rates))
        width = 0.35
        
        bars1 = ax1.bar(x - width/2, rates, width, label='D√©bit inject√© (pps)', 
                       color='skyblue', alpha=0.8, edgecolor='navy')
        bars2 = ax1.bar(x + width/2, measured_rates, width, label='D√©bit mesur√© (pps)', 
                       color='lightcoral', alpha=0.8, edgecolor='darkred')
        
        ax1.set_xlabel('Tests par d√©bit', fontweight='bold')
        ax1.set_ylabel('D√©bit (pps)', fontweight='bold')
        ax1.set_title('Comparaison Histogramme: D√©bit Inject√© vs D√©bit Mesur√©\nSnort 3 - Performance r√©elle', 
                     fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels([f'{r} pps' for r in rates])
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        
        # Annotations avec valeurs exactes
        for i, (bar1, bar2, rate, measured) in enumerate(zip(bars1, bars2, rates, measured_rates)):
            ax1.annotate(f'{rate}', (bar1.get_x() + bar1.get_width()/2, bar1.get_height()),
                        ha='center', va='bottom', fontweight='bold', color='navy')
            ax1.annotate(f'{measured:.0f}', (bar2.get_x() + bar2.get_width()/2, bar2.get_height()),
                        ha='center', va='bottom', fontweight='bold', color='darkred')
        
        # Graphique 2: Histogramme efficacit√© en pourcentage
        bars3 = ax2.bar(range(len(rates)), efficiencies, color='gold', alpha=0.8, edgecolor='orange')
        ax2.set_xlabel('Tests par d√©bit', fontweight='bold')
        ax2.set_ylabel('Efficacit√© (%)', fontweight='bold')
        ax2.set_title('Efficacit√© de D√©bit par Test\nPourcentage du d√©bit th√©orique atteint', 
                     fontsize=14, fontweight='bold')
        ax2.set_xticks(range(len(rates)))
        ax2.set_xticklabels([f'{r} pps' for r in rates])
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim(0, 100)
        
        # Ligne de r√©f√©rence √† 100%
        ax2.axhline(y=100, color='green', linestyle='--', alpha=0.7, label='Efficacit√© id√©ale (100%)')
        ax2.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='Seuil acceptable (80%)')
        ax2.legend()
        
        # Annotations efficacit√©
        for bar, eff in zip(bars3, efficiencies):
            ax2.annotate(f'{eff:.1f}%', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                        ha='center', va='bottom', fontweight='bold', color='darkorange')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_debit_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_debit_comparison.png")
    
    def create_histogram_cpu_analysis(self):
        """
        HISTOGRAMME 2: Analyse compl√®te CPU avec ratios comparatifs
        
        Quatre histogrammes montrant les aspects CPU critiques:
        - Temps CPU User vs System
        - Charge CPU r√©elle en %
        - Paquets par seconde de CPU
        - Temps CPU par paquet
        """
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        
        rates = [d['rate_pps'] for d in self.data]
        cpu_user_sec = [d['cpu_user_sec'] for d in self.data]
        cpu_sys_sec = [d['cpu_sys_sec'] for d in self.data]
        cpu_loads = [d['cpu_load_pct'] for d in self.data]
        packets_per_cpu_sec = [d['packets_per_cpu_sec'] for d in self.data]
        cpu_time_per_packet = [d['cpu_time_per_packet_usec'] for d in self.data]
        
        # Histogramme 1: Temps CPU User vs System
        x = np.arange(len(rates))
        width = 0.35
        
        bars1 = axes[0,0].bar(x - width/2, cpu_user_sec, width, label='CPU User (sec)', 
                             color='lightblue', alpha=0.8, edgecolor='blue')
        bars2 = axes[0,0].bar(x + width/2, cpu_sys_sec, width, label='CPU System (sec)', 
                             color='lightpink', alpha=0.8, edgecolor='red')
        
        axes[0,0].set_title('Temps CPU: User vs System\nComparaison par d√©bit test√©', fontweight='bold')
        axes[0,0].set_xlabel('D√©bits test√©s')
        axes[0,0].set_ylabel('Temps CPU (secondes)')
        axes[0,0].set_xticks(x)
        axes[0,0].set_xticklabels([f'{r} pps' for r in rates])
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations temps CPU
        for bar1, bar2, user, sys in zip(bars1, bars2, cpu_user_sec, cpu_sys_sec):
            axes[0,0].annotate(f'{user:.1f}s', (bar1.get_x() + bar1.get_width()/2, bar1.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='blue')
            axes[0,0].annotate(f'{sys:.1f}s', (bar2.get_x() + bar2.get_width()/2, bar2.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='red')
        
        # Histogramme 2: Charge CPU r√©elle (%)
        bars3 = axes[0,1].bar(rates, cpu_loads, color='green', alpha=0.7, edgecolor='darkgreen')
        axes[0,1].set_title('Charge CPU R√©elle\nPourcentage d\'utilisation processeur', fontweight='bold')
        axes[0,1].set_xlabel('D√©bit inject√© (pps)')
        axes[0,1].set_ylabel('Charge CPU (%)')
        axes[0,1].grid(True, alpha=0.3, axis='y')
        axes[0,1].set_ylim(0, max(cpu_loads) * 1.2)
        
        # Lignes de r√©f√©rence
        axes[0,1].axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Charge mod√©r√©e (50%)')
        axes[0,1].axhline(y=80, color='red', linestyle='--', alpha=0.7, label='Charge √©lev√©e (80%)')
        axes[0,1].legend()
        
        # Annotations charge CPU
        for bar, load in zip(bars3, cpu_loads):
            axes[0,1].annotate(f'{load:.1f}%', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='darkgreen')
        
        # Histogramme 3: Paquets par seconde de CPU (efficacit√© CPU)
        bars4 = axes[1,0].bar(rates, packets_per_cpu_sec, color='purple', alpha=0.7, edgecolor='darkmagenta')
        axes[1,0].set_title('Efficacit√© CPU\nPaquets trait√©s par seconde de CPU', fontweight='bold')
        axes[1,0].set_xlabel('D√©bit inject√© (pps)')
        axes[1,0].set_ylabel('Paquets/sec de CPU')
        axes[1,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations efficacit√© CPU
        for bar, pps in zip(bars4, packets_per_cpu_sec):
            axes[1,0].annotate(f'{pps:.0f}', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='darkmagenta')
        
        # Histogramme 4: Temps CPU par paquet (¬µs/paquet)
        bars5 = axes[1,1].bar(rates, cpu_time_per_packet, color='orange', alpha=0.7, edgecolor='darkorange')
        axes[1,1].set_title('Temps CPU par Paquet\nCo√ªt en ¬µs CPU par paquet trait√©', fontweight='bold')
        axes[1,1].set_xlabel('D√©bit inject√© (pps)')
        axes[1,1].set_ylabel('Temps CPU (¬µs/paquet)')
        axes[1,1].grid(True, alpha=0.3, axis='y')
        
        # Annotations temps par paquet
        for bar, time_pkt in zip(bars5, cpu_time_per_packet):
            axes[1,1].annotate(f'{time_pkt:.1f}¬µs', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='darkorange')
        
        fig.suptitle('Analyse CPU Compl√®te - Histogrammes Comparatifs\nSnort 3 - Performance processeur d√©taill√©e', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_cpu_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_cpu_analysis.png")
    
    def create_histogram_packets_cpu_ratios(self):
        """
        HISTOGRAMME 3: Ratios Paquets/CPU ultra d√©taill√©s
        
        Comparaison directe des ratios critiques:
        - Paquets/sec CPU vs Paquets/sec Runtime
        - Ratio efficacit√© CPU/Runtime
        - Comparaison User vs System CPU par paquet
        """
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        
        rates = [d['rate_pps'] for d in self.data]
        packets_per_cpu_sec = [d['packets_per_cpu_sec'] for d in self.data]
        packets_per_runtime_sec = [d['packets_per_runtime_sec'] for d in self.data]
        cpu_efficiency_ratio = [d['cpu_efficiency_ratio'] for d in self.data]
        cpu_user_per_pkt = [d['cpu_user_time_per_packet_usec'] for d in self.data]
        cpu_sys_per_pkt = [d['cpu_sys_time_per_packet_usec'] for d in self.data]
        
        # Histogramme 1: Paquets/sec CPU vs Runtime (comparaison directe)
        x = np.arange(len(rates))
        width = 0.35
        
        bars1 = axes[0,0].bar(x - width/2, packets_per_cpu_sec, width, 
                             label='Paquets/sec CPU', color='cyan', alpha=0.8, edgecolor='teal')
        bars2 = axes[0,0].bar(x + width/2, packets_per_runtime_sec, width, 
                             label='Paquets/sec Runtime', color='yellow', alpha=0.8, edgecolor='gold')
        
        axes[0,0].set_title('Comparaison Paquets/seconde\nCPU vs Runtime - Efficacit√© relative', fontweight='bold')
        axes[0,0].set_xlabel('D√©bits test√©s')
        axes[0,0].set_ylabel('Paquets par seconde')
        axes[0,0].set_xticks(x)
        axes[0,0].set_xticklabels([f'{r} pps' for r in rates])
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations comparaison
        for i, (bar1, bar2, cpu_pps, rt_pps) in enumerate(zip(bars1, bars2, packets_per_cpu_sec, packets_per_runtime_sec)):
            axes[0,0].annotate(f'{cpu_pps:.0f}', (bar1.get_x() + bar1.get_width()/2, bar1.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='teal')
            axes[0,0].annotate(f'{rt_pps:.0f}', (bar2.get_x() + bar2.get_width()/2, bar2.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='gold')
        
        # Histogramme 2: Ratio efficacit√© CPU/Runtime
        bars3 = axes[0,1].bar(rates, cpu_efficiency_ratio, color='magenta', alpha=0.7, edgecolor='purple')
        axes[0,1].set_title('Ratio Efficacit√© CPU/Runtime\nFacteur de performance CPU', fontweight='bold')
        axes[0,1].set_xlabel('D√©bit inject√© (pps)')
        axes[0,1].set_ylabel('Ratio Efficacit√©')
        axes[0,1].grid(True, alpha=0.3, axis='y')
        
        # Ligne de r√©f√©rence ratio optimal
        axes[0,1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Ratio optimal (1.0)')
        axes[0,1].legend()
        
        # Annotations ratio
        for bar, ratio in zip(bars3, cpu_efficiency_ratio):
            axes[0,1].annotate(f'{ratio:.2f}', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='purple')
        
        # Histogramme 3: CPU User vs System par paquet
        bars4 = axes[1,0].bar(x - width/2, cpu_user_per_pkt, width, 
                             label='CPU User (¬µs/pkt)', color='lightsteelblue', alpha=0.8, edgecolor='navy')
        bars5 = axes[1,0].bar(x + width/2, cpu_sys_per_pkt, width, 
                             label='CPU System (¬µs/pkt)', color='mistyrose', alpha=0.8, edgecolor='crimson')
        
        axes[1,0].set_title('Temps CPU par Paquet\nUser vs System - R√©partition d√©taill√©e', fontweight='bold')
        axes[1,0].set_xlabel('D√©bits test√©s')
        axes[1,0].set_ylabel('Temps CPU (¬µs/paquet)')
        axes[1,0].set_xticks(x)
        axes[1,0].set_xticklabels([f'{r} pps' for r in rates])
        axes[1,0].legend()
        axes[1,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations User/System
        for bar4, bar5, user, sys in zip(bars4, bars5, cpu_user_per_pkt, cpu_sys_per_pkt):
            axes[1,0].annotate(f'{user:.1f}', (bar4.get_x() + bar4.get_width()/2, bar4.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='navy')
            axes[1,0].annotate(f'{sys:.1f}', (bar5.get_x() + bar5.get_width()/2, bar5.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='crimson')
        
        # Histogramme 4: Ratio User/System global
        user_sys_ratios = [d['cpu_user_sys_ratio'] for d in self.data]
        bars6 = axes[1,1].bar(rates, user_sys_ratios, color='brown', alpha=0.7, edgecolor='maroon')
        axes[1,1].set_title('Ratio CPU User/System\n√âquilibre User vs Kernel', fontweight='bold')
        axes[1,1].set_xlabel('D√©bit inject√© (pps)')
        axes[1,1].set_ylabel('Ratio User/System')
        axes[1,1].grid(True, alpha=0.3, axis='y')
        
        # Ligne de r√©f√©rence √©quilibre
        axes[1,1].axhline(y=1, color='green', linestyle='--', alpha=0.7, label='√âquilibre (1.0)')
        axes[1,1].legend()
        
        # Annotations ratio User/System
        for bar, ratio in zip(bars6, user_sys_ratios):
            axes[1,1].annotate(f'{ratio:.2f}', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='maroon')
        
        fig.suptitle('Ratios Paquets/CPU - Analyse Comparative Avanc√©e\nSnort 3 - M√©triques d\'efficacit√© d√©taill√©es', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_packets_cpu_ratios.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_packets_cpu_ratios.png")
    
    def create_histogram_modules_comparison(self):
        """
        HISTOGRAMME 4: Comparaison d√©taill√©e des modules Snort
        
        Analyse comparative des performances des modules:
        - Detection vs Port Scan vs Stream
        - Efficacit√© par module
        - Ratios inter-modules
        """
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        
        rates = [d['rate_pps'] for d in self.data]
        detection_analyzed = [d['detection_analyzed'] for d in self.data]
        port_scan_packets = [d['port_scan_packets'] for d in self.data]
        stream_flows = [d['stream_flows'] for d in self.data]
        arp_spoof_packets = [d['arp_spoof_packets'] for d in self.data]
        detection_pps = [d['detection_pps'] for d in self.data]
        flows_per_sec = [d['flows_per_sec'] for d in self.data]
        packets_per_flow = [d['packets_per_flow'] for d in self.data]
        
        # Histogramme 1: Comparaison volumes des modules principaux
        x = np.arange(len(rates))
        width = 0.2
        
        bars1 = axes[0,0].bar(x - width, detection_analyzed, width, 
                             label='Detection analyzed', color='lightcoral', alpha=0.8)
        bars2 = axes[0,0].bar(x, port_scan_packets, width, 
                             label='Port Scan packets', color='lightgreen', alpha=0.8)
        bars3 = axes[0,0].bar(x + width, arp_spoof_packets, width, 
                             label='ARP Spoof packets', color='lightblue', alpha=0.8)
        
        axes[0,0].set_title('Volume de Paquets par Module\nComparaison Detection, Port Scan, ARP Spoof', fontweight='bold')
        axes[0,0].set_xlabel('D√©bits test√©s')
        axes[0,0].set_ylabel('Nombre de paquets')
        axes[0,0].set_xticks(x)
        axes[0,0].set_xticklabels([f'{r} pps' for r in rates])
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations modules
        for i, (bar1, bar2, bar3, det, port, arp) in enumerate(zip(bars1, bars2, bars3, 
                                                                  detection_analyzed, port_scan_packets, arp_spoof_packets)):
            if det > 0:
                axes[0,0].annotate(f'{det:,}', (bar1.get_x() + bar1.get_width()/2, bar1.get_height()),
                                  ha='center', va='bottom', fontsize=9, rotation=45)
            if port > 0:
                axes[0,0].annotate(f'{port:,}', (bar2.get_x() + bar2.get_width()/2, bar2.get_height()),
                                  ha='center', va='bottom', fontsize=9, rotation=45)
            if arp > 0:
                axes[0,0].annotate(f'{arp:,}', (bar3.get_x() + bar3.get_width()/2, bar3.get_height()),
                                  ha='center', va='bottom', fontsize=9, rotation=45)
        
        # Histogramme 2: Flux Stream et efficacit√©
        bars4 = axes[0,1].bar(x - width/2, stream_flows, width, 
                             label='Stream flows', color='gold', alpha=0.8)
        bars5 = axes[0,1].bar(x + width/2, flows_per_sec, width, 
                             label='Flows/sec', color='orange', alpha=0.8)
        
        axes[0,1].set_title('Analyse des Flux Stream\nVolume total vs D√©bit de cr√©ation', fontweight='bold')
        axes[0,1].set_xlabel('D√©bits test√©s')
        axes[0,1].set_ylabel('Nombre de flux')
        axes[0,1].set_xticks(x)
        axes[0,1].set_xticklabels([f'{r} pps' for r in rates])
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3, axis='y')
        
        # Annotations flux
        for bar4, bar5, flows, fps in zip(bars4, bars5, stream_flows, flows_per_sec):
            axes[0,1].annotate(f'{flows}', (bar4.get_x() + bar4.get_width()/2, bar4.get_height()),
                              ha='center', va='bottom', fontweight='bold')
            axes[0,1].annotate(f'{fps:.1f}', (bar5.get_x() + bar5.get_width()/2, bar5.get_height()),
                              ha='center', va='bottom', fontweight='bold')
        
        # Histogramme 3: Efficacit√© Detection (pps)
        bars6 = axes[1,0].bar(rates, detection_pps, color='purple', alpha=0.7, edgecolor='darkmagenta')
        axes[1,0].set_title('Efficacit√© Module Detection\nPaquets analys√©s par seconde', fontweight='bold')
        axes[1,0].set_xlabel('D√©bit inject√© (pps)')
        axes[1,0].set_ylabel('Detection pps')
        axes[1,0].grid(True, alpha=0.3, axis='y')
        
        # Annotations efficacit√© detection
        for bar, pps in zip(bars6, detection_pps):
            axes[1,0].annotate(f'{pps:.0f}', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='darkmagenta')
        
        # Histogramme 4: Paquets par flux (densit√©)
        bars7 = axes[1,1].bar(rates, packets_per_flow, color='teal', alpha=0.7, edgecolor='darkcyan')
        axes[1,1].set_title('Densit√© des Flux\nPaquets moyens par flux', fontweight='bold')
        axes[1,1].set_xlabel('D√©bit inject√© (pps)')
        axes[1,1].set_ylabel('Paquets/flux')
        axes[1,1].grid(True, alpha=0.3, axis='y')
        
        # Annotations densit√©
        for bar, ppf in zip(bars7, packets_per_flow):
            axes[1,1].annotate(f'{ppf:.1f}', (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color='darkcyan')
        
        fig.suptitle('Analyse Comparative des Modules Snort 3\nPerformance et efficacit√© d√©taill√©es', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_modules_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_modules_comparison.png")
    
    def create_histogram_protocol_analysis(self):
        """
        HISTOGRAMME 5: Analyse d√©taill√©e des protocoles avec comparaisons
        
        Distribution des protocoles r√©seau d√©tect√©s par le codec
        avec analyse comparative entre d√©bits.
        """
        # Collecte de tous les protocoles
        all_protocols = set()
        for d in self.data:
            all_protocols.update(d['codec_data'].keys())
        
        if not all_protocols:
            print("‚ö†Ô∏è  Aucune donn√©e de protocole trouv√©e pour l'histogramme")
            return
        
        # S√©lection des protocoles les plus significatifs
        protocol_totals = {}
        for proto in all_protocols:
            protocol_totals[proto] = sum(d['codec_data'].get(proto, 0) for d in self.data)
        
        # Top 8 protocoles les plus fr√©quents
        top_protocols = sorted(protocol_totals.items(), key=lambda x: x[1], reverse=True)[:8]
        protocols = [p[0] for p in top_protocols]
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        
        rates = [d['rate_pps'] for d in self.data]
        
        # Histogramme 1: Comparaison des top protocoles
        x = np.arange(len(protocols))
        width = 0.25
        colors = ['skyblue', 'lightcoral', 'lightgreen']
        
        for i, rate in enumerate(rates):
            data_for_rate = next(d for d in self.data if d['rate_pps'] == rate)
            counts = [data_for_rate['codec_data'].get(proto, 0) for proto in protocols]
            
            offset = (i - len(rates)//2) * width
            bars = axes[0,0].bar(x + offset, counts, width, 
                               label=f'{rate} pps', alpha=0.8, color=colors[i % len(colors)])
            
            # Annotations pour valeurs significatives
            for j, (bar, count) in enumerate(zip(bars, counts)):
                if count > 1000:  # Annoter seulement les valeurs importantes
                    axes[0,0].annotate(f'{count:,}', 
                                      (bar.get_x() + bar.get_width()/2, bar.get_height()), 
                                      ha='center', va='bottom', rotation=45, fontsize=8)
        
        axes[0,0].set_title('Distribution des Top Protocoles\nComparaison par d√©bit test√©', fontweight='bold')
        axes[0,0].set_xlabel('Protocoles r√©seau')
        axes[0,0].set_ylabel('Nombre de paquets d√©tect√©s')
        axes[0,0].set_xticks(x)
        axes[0,0].set_xticklabels(protocols, rotation=45, ha='right')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3, axis='y')
        
        # Histogramme 2: Pourcentage de distribution pour chaque d√©bit
        for i, rate in enumerate(rates):
            data_for_rate = next(d for d in self.data if d['rate_pps'] == rate)
            total_packets = sum(data_for_rate['codec_data'].values())
            
            if total_packets > 0:
                percentages = [(data_for_rate['codec_data'].get(proto, 0) / total_packets) * 100 
                              for proto in protocols]
                
                axes[0,1].bar(x + i * width - width, percentages, width, 
                             label=f'{rate} pps', alpha=0.8, color=colors[i % len(colors)])
        
        axes[0,1].set_title('Distribution Relative des Protocoles\nPourcentage par d√©bit', fontweight='bold')
        axes[0,1].set_xlabel('Protocoles r√©seau')
        axes[0,1].set_ylabel('Pourcentage (%)')
        axes[0,1].set_xticks(x)
        axes[0,1].set_xticklabels(protocols, rotation=45, ha='right')
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3, axis='y')
        
        # Histogramme 3: Focus sur les protocoles principaux (ARP, ETH, IPv4, IPv6)
        main_protocols = ['arp', 'eth', 'ipv4', 'ipv6', 'tcp', 'udp']
        existing_main = [p for p in main_protocols if p in all_protocols]
        
        if existing_main:
            x_main = np.arange(len(existing_main))
            
            for i, rate in enumerate(rates):
                data_for_rate = next(d for d in self.data if d['rate_pps'] == rate)
                counts_main = [data_for_rate['codec_data'].get(proto, 0) for proto in existing_main]
                
                axes[1,0].bar(x_main + i * width - width/2, counts_main, width, 
                             label=f'{rate} pps', alpha=0.8, color=colors[i % len(colors)])
            
            axes[1,0].set_title('Protocoles Principaux\nARP, ETH, IPv4, IPv6, TCP, UDP', fontweight='bold')
            axes[1,0].set_xlabel('Protocoles principaux')
            axes[1,0].set_ylabel('Nombre de paquets')
            axes[1,0].set_xticks(x_main)
            axes[1,0].set_xticklabels(existing_main)
            axes[1,0].legend()
            axes[1,0].grid(True, alpha=0.3, axis='y')
        
        # Histogramme 4: √âvolution des protocoles avec le d√©bit
        if 'arp' in all_protocols and 'ipv4' in all_protocols:
            arp_counts = [d['codec_data'].get('arp', 0) for d in self.data]
            ipv4_counts = [d['codec_data'].get('ipv4', 0) for d in self.data]
            tcp_counts = [d['codec_data'].get('tcp', 0) for d in self.data]
            udp_counts = [d['codec_data'].get('udp', 0) for d in self.data]
            
            x_evo = np.arange(len(rates))
            width_evo = 0.2
            
            axes[1,1].bar(x_evo - 1.5*width_evo, arp_counts, width_evo, 
                         label='ARP', alpha=0.8, color='gold')
            axes[1,1].bar(x_evo - 0.5*width_evo, ipv4_counts, width_evo, 
                         label='IPv4', alpha=0.8, color='lightblue')
            axes[1,1].bar(x_evo + 0.5*width_evo, tcp_counts, width_evo, 
                         label='TCP', alpha=0.8, color='lightcoral')
            axes[1,1].bar(x_evo + 1.5*width_evo, udp_counts, width_evo, 
                         label='UDP', alpha=0.8, color='lightgreen')
            
            axes[1,1].set_title('√âvolution Protocoles vs D√©bit\nARP, IPv4, TCP, UDP', fontweight='bold')
            axes[1,1].set_xlabel('D√©bits test√©s')
            axes[1,1].set_ylabel('Nombre de paquets')
            axes[1,1].set_xticks(x_evo)
            axes[1,1].set_xticklabels([f'{r} pps' for r in rates])
            axes[1,1].legend()
            axes[1,1].grid(True, alpha=0.3, axis='y')
        
        fig.suptitle('Analyse D√©taill√©e des Protocoles R√©seau\nCodec Snort 3 - Distribution comparative', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_protocol_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_protocol_analysis.png")
    
    def create_histogram_performance_summary(self):
        """
        HISTOGRAMME 6: R√©sum√© de performance avec m√©triques cl√©s
        
        Vue d'ensemble avec les 4 m√©triques les plus importantes
        sous forme d'histogrammes comparatifs.
        """
        fig, axes = plt.subplots(2, 2, figsize=(18, 14))
        
        rates = [d['rate_pps'] for d in self.data]
        throughput_eff = [d['throughput_efficiency_pct'] for d in self.data]
        packet_loss = [d['packet_loss_pct'] for d in self.data]
        cpu_load = [d['cpu_load_pct'] for d in self.data]
        detection_eff = [d['detection_efficiency_pct'] for d in self.data]
        
        # Histogramme 1: Efficacit√© de d√©bit (m√©trique principale)
        bars1 = axes[0,0].bar(rates, throughput_eff, color='green', alpha=0.7, edgecolor='darkgreen')
        axes[0,0].set_title('üéØ Efficacit√© de D√©bit\nPourcentage du d√©bit th√©orique atteint', fontweight='bold')
        axes[0,0].set_xlabel('D√©bit inject√© (pps)')
        axes[0,0].set_ylabel('Efficacit√© (%)')
        axes[0,0].set_ylim(0, 100)
        axes[0,0].grid(True, alpha=0.3, axis='y')
        
        # Lignes de r√©f√©rence efficacit√©
        axes[0,0].axhline(y=100, color='blue', linestyle='--', alpha=0.7, label='Id√©al (100%)')
        axes[0,0].axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='Bon (80%)')
        axes[0,0].axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Acceptable (50%)')
        axes[0,0].legend()
        
        # Annotations avec couleurs selon performance
        for bar, eff in zip(bars1, throughput_eff):
            color = 'green' if eff >= 80 else 'orange' if eff >= 50 else 'red'
            axes[0,0].annotate(f'{eff:.1f}%', 
                              (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color=color)
        
        # Histogramme 2: Perte de paquets (inverse de l'efficacit√©)
        bars2 = axes[0,1].bar(rates, packet_loss, color='red', alpha=0.7, edgecolor='darkred')
        axes[0,1].set_title('‚ùå Perte de Paquets\nPourcentage de paquets non trait√©s', fontweight='bold')
        axes[0,1].set_xlabel('D√©bit inject√© (pps)')
        axes[0,1].set_ylabel('Perte (%)')
        axes[0,1].set_ylim(0, 100)
        axes[0,1].grid(True, alpha=0.3, axis='y')
        
        # Lignes de r√©f√©rence pertes
        axes[0,1].axhline(y=5, color='green', linestyle='--', alpha=0.7, label='Acceptable (<5%)')
        axes[0,1].axhline(y=20, color='orange', linestyle='--', alpha=0.7, label='Limite (20%)')
        axes[0,1].axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Critique (50%)')
        axes[0,1].legend()
        
               # Annotations pertes
        for bar, loss in zip(bars2, packet_loss):
            color = 'green' if loss <= 5 else 'orange' if loss <= 20 else 'red'
            axes[0,1].annotate(f'{loss:.1f}%', 
                              (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color=color)
        
        # Histogramme 3: Charge CPU r√©elle
        bars3 = axes[1,0].bar(rates, cpu_load, color='blue', alpha=0.7, edgecolor='navy')
        axes[1,0].set_title('‚ö° Charge CPU R√©elle\nPourcentage d\'utilisation processeur', fontweight='bold')
        axes[1,0].set_xlabel('D√©bit inject√© (pps)')
        axes[1,0].set_ylabel('Charge CPU (%)')
        axes[1,0].grid(True, alpha=0.3, axis='y')
        
        # Lignes de r√©f√©rence CPU
        axes[1,0].axhline(y=25, color='green', linestyle='--', alpha=0.7, label='Faible (25%)')
        axes[1,0].axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Mod√©r√©e (50%)')
        axes[1,0].axhline(y=80, color='red', linestyle='--', alpha=0.7, label='√âlev√©e (80%)')
        axes[1,0].legend()
        
        # Annotations CPU
        for bar, load in zip(bars3, cpu_load):
            color = 'green' if load <= 25 else 'orange' if load <= 50 else 'red'
            axes[1,0].annotate(f'{load:.1f}%', 
                              (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color=color)
        
        # Histogramme 4: Efficacit√© Detection
        bars4 = axes[1,1].bar(rates, detection_eff, color='purple', alpha=0.7, edgecolor='darkmagenta')
        axes[1,1].set_title('üîç Efficacit√© D√©tection\nPourcentage du trafic analys√©', fontweight='bold')
        axes[1,1].set_xlabel('D√©bit inject√© (pps)')
        axes[1,1].set_ylabel('D√©tection (%)')
        axes[1,1].set_ylim(0, max(detection_eff) * 1.1 if detection_eff else 100)
        axes[1,1].grid(True, alpha=0.3, axis='y')
        
        # Lignes de r√©f√©rence detection
        axes[1,1].axhline(y=95, color='green', linestyle='--', alpha=0.7, label='Excellent (95%)')
        axes[1,1].axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='Bon (80%)')
        axes[1,1].axhline(y=60, color='red', linestyle='--', alpha=0.7, label='Limite (60%)')
        axes[1,1].legend()
        
        # Annotations detection
        for bar, det_eff in zip(bars4, detection_eff):
            color = 'green' if det_eff >= 95 else 'orange' if det_eff >= 80 else 'red'
            axes[1,1].annotate(f'{det_eff:.1f}%', 
                              (bar.get_x() + bar.get_width()/2, bar.get_height()),
                              ha='center', va='bottom', fontweight='bold', color=color)
        
        fig.suptitle('üìä R√âSUM√â DE PERFORMANCE SNORT 3 - M√©triques Cl√©s\nVue d\'ensemble comparative des 4 indicateurs critiques', 
                    fontsize=16, fontweight='bold')
        
        # Note explicative globale
        plt.figtext(0.02, 0.02, 
                   "üî• CODE COULEUR: Vert=Excellent, Orange=Acceptable, Rouge=Probl√©matique | "
                   "M√©triques essentielles pour √©valuer les performances Snort",
                   fontsize=11, style='italic', weight='bold')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'histogram_performance_summary.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üìä Histogramme sauvegard√©: histogram_performance_summary.png")
    
    def create_ultimate_comparison_histogram(self):
        """
        HISTOGRAMME 7 (ULTIME): Comparaison TOTALE avec tous les ratios critiques
        
        L'histogramme le plus complet avec 6 m√©triques comparatives essentielles
        pour une analyse exhaustive des performances.
        """
        fig = plt.figure(figsize=(24, 18))
        
        # Cr√©ation d'une grille 3x2 pour 6 graphiques
        gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)
        
        rates = [d['rate_pps'] for d in self.data]
        
        # === M√âTRIQUES POUR COMPARAISON ULTIME ===
        debit_measured = [d['debit_avg_pps'] for d in self.data]
        packets_per_cpu_sec = [d['packets_per_cpu_sec'] for d in self.data]
        packets_per_runtime_sec = [d['packets_per_runtime_sec'] for d in self.data]
        cpu_time_per_packet = [d['cpu_time_per_packet_usec'] for d in self.data]
        detection_analyzed = [d['detection_analyzed'] for d in self.data]
        throughput_eff = [d['throughput_efficiency_pct'] for d in self.data]
        
        # GRAPHIQUE 1: D√©bit mesur√© vs inject√© (COMPARAISON DIRECTE)
        ax1 = fig.add_subplot(gs[0, 0])
        x = np.arange(len(rates))
        width = 0.35
        
        bars1a = ax1.bar(x - width/2, rates, width, label='D√©bit inject√©', 
                        color='lightblue', alpha=0.8, edgecolor='blue')
        bars1b = ax1.bar(x + width/2, debit_measured, width, label='D√©bit mesur√©', 
                        color='orange', alpha=0.8, edgecolor='darkorange')
        
        ax1.set_title('üìà D√âBIT: Inject√© vs Mesur√©\nComparaison directe des performances', 
                     fontweight='bold', fontsize=12)
        ax1.set_xlabel('Tests')
        ax1.set_ylabel('D√©bit (pps)')
        ax1.set_xticks(x)
        ax1.set_xticklabels([f'{r}pps' for r in rates])
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        
        # Annotations avec √©carts
        for i, (rate, measured) in enumerate(zip(rates, debit_measured)):
            loss = ((rate - measured) / rate) * 100
            ax1.annotate(f'-{loss:.1f}%', (i, max(rate, measured) + max(rates)*0.05),
                        ha='center', fontweight='bold', color='red')
        
        # GRAPHIQUE 2: Paquets/sec CPU vs Runtime (EFFICACIT√â COMPARATIVE)
        ax2 = fig.add_subplot(gs[0, 1])
        
        bars2a = ax2.bar(x - width/2, packets_per_cpu_sec, width, label='Paquets/sec CPU', 
                        color='green', alpha=0.8, edgecolor='darkgreen')
        bars2b = ax2.bar(x + width/2, packets_per_runtime_sec, width, label='Paquets/sec Runtime', 
                        color='red', alpha=0.8, edgecolor='darkred')
        
        ax2.set_title('‚ö° EFFICACIT√â: CPU vs Runtime\nComparaison des d√©bits de traitement', 
                     fontweight='bold', fontsize=12)
        ax2.set_xlabel('Tests')
        ax2.set_ylabel('Paquets/seconde')
        ax2.set_xticks(x)
        ax2.set_xticklabels([f'{r}pps' for r in rates])
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        
        # Annotations ratios
        for i, (cpu_pps, rt_pps) in enumerate(zip(packets_per_cpu_sec, packets_per_runtime_sec)):
            ratio = cpu_pps / rt_pps if rt_pps > 0 else 0
            ax2.annotate(f'√ó{ratio:.1f}', (i, max(cpu_pps, rt_pps) + max(packets_per_cpu_sec)*0.05),
                        ha='center', fontweight='bold', color='purple')
        
        # GRAPHIQUE 3: Temps CPU par paquet (CO√õT UNITAIRE)
        ax3 = fig.add_subplot(gs[1, 0])
        
        bars3 = ax3.bar(rates, cpu_time_per_packet, color='purple', alpha=0.8, edgecolor='darkmagenta')
        ax3.set_title('üïê CO√õT CPU par Paquet\nTemps de traitement unitaire', 
                     fontweight='bold', fontsize=12)
        ax3.set_xlabel('D√©bit inject√© (pps)')
        ax3.set_ylabel('Temps CPU (¬µs/paquet)')
        ax3.grid(True, alpha=0.3, axis='y')
        
        # Annotations avec tendance
        for i, (bar, time_pkt) in enumerate(zip(bars3, cpu_time_per_packet)):
            ax3.annotate(f'{time_pkt:.1f}¬µs', 
                        (bar.get_x() + bar.get_width()/2, bar.get_height()),
                        ha='center', va='bottom', fontweight='bold')
            
            # Indication de tendance
            if i > 0:
                prev_time = cpu_time_per_packet[i-1]
                trend = "‚Üó" if time_pkt > prev_time else "‚Üò" if time_pkt < prev_time else "‚Üí"
                ax3.annotate(trend, (bar.get_x() + bar.get_width()/2, bar.get_height() * 0.7),
                            ha='center', fontsize=16, color='red' if trend == "‚Üó" else 'green')
        
        # GRAPHIQUE 4: Detection Analyzed (VOLUME DE TRAVAIL)
        ax4 = fig.add_subplot(gs[1, 1])
        
        bars4 = ax4.bar(rates, detection_analyzed, color='teal', alpha=0.8, edgecolor='darkcyan')
        ax4.set_title('üîç VOLUME D√©tection\nPaquets analys√©s par le moteur', 
                     fontweight='bold', fontsize=12)
        ax4.set_xlabel('D√©bit inject√© (pps)')
        ax4.set_ylabel('Paquets analys√©s')
        ax4.grid(True, alpha=0.3, axis='y')
        
        # Annotations avec pourcentage du d√©bit inject√©
        for bar, analyzed, rate in zip(bars4, detection_analyzed, rates):
            percentage = (analyzed / (rate * self.data[rates.index(rate)]['runtime_sec'])) * 100 if rate > 0 else 0
            ax4.annotate(f'{analyzed:,}\n({percentage:.1f}%)', 
                        (bar.get_x() + bar.get_width()/2, bar.get_height()),
                        ha='center', va='bottom', fontweight='bold')
        
        # GRAPHIQUE 5: Efficacit√© globale (PERFORMANCE RELATIVE)
        ax5 = fig.add_subplot(gs[2, :])  # Graphique sur toute la largeur
        
        # M√©triques normalis√©es pour comparaison (0-100)
        eff_debit_norm = throughput_eff  # D√©j√† en %
        eff_cpu_norm = [min((pps / 10000) * 100, 100) for pps in packets_per_cpu_sec]  # Normalis√© arbitrairement
        eff_detection_norm = [(analyzed / (rate * runtime)) * 100 if rate > 0 else 0 
                             for analyzed, rate, runtime in zip(detection_analyzed, rates, 
                                                               [d['runtime_sec'] for d in self.data])]
        
        x_wide = np.arange(len(rates))
        width_wide = 0.25
        
        bars5a = ax5.bar(x_wide - width_wide, eff_debit_norm, width_wide, 
                        label='Efficacit√© D√©bit (%)', color='blue', alpha=0.7)
        bars5b = ax5.bar(x_wide, eff_cpu_norm, width_wide, 
                        label='Efficacit√© CPU (normalis√©e)', color='green', alpha=0.7)
        bars5c = ax5.bar(x_wide + width_wide, eff_detection_norm, width_wide, 
                        label='Efficacit√© D√©tection (%)', color='red', alpha=0.7)
        
        ax5.set_title('üèÜ EFFICACIT√â GLOBALE COMPARATIVE\nTrois dimensions de performance normalis√©es', 
                     fontweight='bold', fontsize=14)
        ax5.set_xlabel('D√©bits test√©s', fontweight='bold')
        ax5.set_ylabel('Efficacit√© normalis√©e (%)', fontweight='bold')
        ax5.set_xticks(x_wide)
        ax5.set_xticklabels([f'{r} pps' for r in rates])
        ax5.legend(loc='upper right')
        ax5.grid(True, alpha=0.3, axis='y')
        ax5.set_ylim(0, 120)
        
        # Lignes de r√©f√©rence performance
        ax5.axhline(y=100, color='gold', linestyle='--', alpha=0.8, linewidth=2, label='Performance id√©ale')
        ax5.axhline(y=80, color='orange', linestyle='--', alpha=0.6, label='Performance acceptable')
        ax5.axhline(y=50, color='red', linestyle='--', alpha=0.6, label='Performance limite')
        
        # Annotations finales avec scores globaux
        for i, (debit_eff, cpu_eff, det_eff) in enumerate(zip(eff_debit_norm, eff_cpu_norm, eff_detection_norm)):
            score_global = (debit_eff + cpu_eff + det_eff) / 3
            ax5.annotate(f'Score: {score_global:.1f}', 
                        (i, max(debit_eff, cpu_eff, det_eff) + 10),
                        ha='center', fontweight='bold', fontsize=11,
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        
        # Titre et notes finales
        fig.suptitle('üî• ANALYSE ULTIME SNORT 3 - COMPARAISON EXHAUSTIVE üî•\n'
                    'Histogrammes comparatifs complets pour √©valuation de performance', 
                    fontsize=18, fontweight='bold', color='darkblue')
        
        plt.figtext(0.02, 0.02, 
                   "üí° L√âGENDE: Ce graphique compile TOUTES les m√©triques critiques pour une analyse compl√®te. "
                   "Score global = moyenne des 3 efficacit√©s principales.",
                   fontsize=12, style='italic', weight='bold', color='darkgreen')
        
        plt.savefig(self.figures_dir / 'histogram_ultimate_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("üî• Histogramme ULTIME sauvegard√©: histogram_ultimate_comparison.png")
    
    def create_summary_dataframe(self) -> pd.DataFrame:
        """
        Cr√©e un DataFrame r√©sum√© COMPLET avec toutes les m√©triques calcul√©es
        """
        df_data = []
        
        for d in self.data:
            row = {
                # === DONN√âES DE BASE ===
                'rate_pps': d['rate_pps'],
                'packets_total': d['packets_total'],
                'runtime_sec': d['runtime_sec'],
                'debit_avg_pps': d['debit_avg_pps'],
                'latency_avg_usecs': d['latency_avg_usecs'],
                'latency_max_usecs': d['latency_max_usecs'],
                
                # === CPU D√âTAILL√â ===
                'cpu_user_usec': d['cpu_user_usec'],
                'cpu_sys_usec': d['cpu_sys_usec'],
                'cpu_total_sec': d['cpu_total_sec'],
                'cpu_load_pct': d['cpu_load_pct'],
                'cpu_time_per_packet_usec': d['cpu_time_per_packet_usec'],
                'cpu_user_sys_ratio': d['cpu_user_sys_ratio'],
                
                # === EFFICACIT√â ===
                'throughput_efficiency_pct': d['throughput_efficiency_pct'],
                'packet_loss_pct': d['packet_loss_pct'],
                'packets_per_cpu_sec': d['packets_per_cpu_sec'],
                'packets_per_runtime_sec': d['packets_per_runtime_sec'],
                'cpu_efficiency_ratio': d['cpu_efficiency_ratio'],
                
                # === MODULES ===
                'detection_analyzed': d['detection_analyzed'],
                'detection_efficiency_pct': d['detection_efficiency_pct'],
                'detection_pps': d['detection_pps'],
                'port_scan_packets': d['port_scan_packets'],
                'port_scan_trackers': d['port_scan_trackers'],
                'stream_flows': d['stream_flows'],
                'flows_per_sec': d['flows_per_sec'],
                'packets_per_flow': d['packets_per_flow'],
                'stream_total_prunes': d['stream_total_prunes'],
                'stream_idle_prunes': d['stream_idle_prunes'],
                'arp_spoof_packets': d['arp_spoof_packets'],
                'binder_raw_packets': d['binder_raw_packets'],
                'binder_new_flows': d['binder_new_flows'],
                'binder_inspects': d['binder_inspects']
            }
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        return df
    
    def print_ultimate_summary_statistics(self, df: pd.DataFrame):
        """
        Affiche des statistiques ULTRA D√âTAILL√âES et analytiques
        """
        print("\n" + "üî•"*100)
        print("üöÄ ANALYSE ULTIME DES PERFORMANCES SNORT 3 - RAPPORT COMPLET üöÄ")
        print("üî•"*100)
        
        print(f"\nüìã CONFIGURATION DES TESTS:")
        print(f"   üéØ Nombre de d√©bits test√©s: {len(df)}")
        print(f"   üéØ D√©bits inject√©s: {', '.join(map(str, sorted(df['rate_pps'].tolist())))} pps")
        print(f"   üéØ Dur√©e totale des tests: {df['runtime_sec'].sum():.0f} secondes ({df['runtime_sec'].sum()/60:.1f} minutes)")
        print(f"   üéØ Paquets totaux trait√©s: {df['packets_total'].sum():,}")
        print(f"   üéØ Temps CPU total consomm√©: {df['cpu_total_sec'].sum():.1f} secondes")
        
        print(f"\nüìä PERFORMANCES MOYENNES GLOBALES:")
        print(f"   üìà D√©bit moyen: {df['debit_avg_pps'].mean():.2f} pps")
        print(f"   üìà Efficacit√© d√©bit moyenne: {df['throughput_efficiency_pct'].mean():.1f}%")
        print(f"   üìà Perte moyenne de paquets: {df['packet_loss_pct'].mean():.1f}%")
        print(f"   üìà Latence moyenne: {df['latency_avg_usecs'].mean():.3f} ¬µs")
        print(f"   üìà Charge CPU moyenne: {df['cpu_load_pct'].mean():.1f}%")
        print(f"   üìà Temps CPU moyen par paquet: {df['cpu_time_per_packet_usec'].mean():.2f} ¬µs/pkt")
        print(f"   üìà Paquets/sec CPU moyen: {df['packets_per_cpu_sec'].mean():.0f} pps")
        print(f"   üìà Efficacit√© d√©tection moyenne: {df['detection_efficiency_pct'].mean():.1f}%")
        
        print(f"\nüèÜ RECORDS DE PERFORMANCE:")
        best_throughput_idx = df['throughput_efficiency_pct'].idxmax()
        best_cpu_eff_idx = df['packets_per_cpu_sec'].idxmax()
        best_detection_idx = df['detection_efficiency_pct'].idxmax()
        lowest_loss_idx = df['packet_loss_pct'].idxmin()
        lowest_latency_idx = df['latency_avg_usecs'].idxmin()
        
        print(f"   ü•á RECORD Efficacit√© d√©bit: {df.loc[best_throughput_idx, 'throughput_efficiency_pct']:.1f}% √† {df.loc[best_throughput_idx, 'rate_pps']:.0f} pps")
        print(f"   ü•á RECORD Efficacit√© CPU: {df.loc[best_cpu_eff_idx, 'packets_per_cpu_sec']:.0f} pkt/sec √† {df.loc[best_cpu_eff_idx, 'rate_pps']:.0f} pps")
        print(f"   ü•á RECORD Efficacit√© d√©tection: {df.loc[best_detection_idx, 'detection_efficiency_pct']:.1f}% √† {df.loc[best_detection_idx, 'rate_pps']:.0f} pps")
        print(f"   ü•á RECORD Perte minimale: {df.loc[lowest_loss_idx, 'packet_loss_pct']:.1f}% √† {df.loc[lowest_loss_idx, 'rate_pps']:.0f} pps")
        print(f"   ü•á RECORD Latence minimale: {df.loc[lowest_latency_idx, 'latency_avg_usecs']:.3f} ¬µs √† {df.loc[lowest_latency_idx, 'rate_pps']:.0f} pps")
        
        print(f"\n‚ö†Ô∏è  ANALYSE DES PROBL√àMES:")
        
        # D√©tection des goulots d'√©tranglement
        critical_loss = df[df['packet_loss_pct'] > 70]
        high_loss = df[df['packet_loss_pct'] > 50]
        low_cpu_high_loss = df[(df['cpu_load_pct'] < 20) & (df['packet_loss_pct'] > 50)]
        high_cpu_low_throughput = df[(df['cpu_load_pct'] > 50) & (df['throughput_efficiency_pct'] < 50)]
        
        if not critical_loss.empty:
            print(f"   üî¥ CRITIQUE: Pertes tr√®s √©lev√©es (>70%) √† {', '.join(map(str, critical_loss['rate_pps'].tolist()))} pps")
        
        if not high_loss.empty:
            print(f"   üü† ATTENTION: Pertes √©lev√©es (>50%) √† {', '.join(map(str, high_loss['rate_pps'].tolist()))} pps")
        
        if not low_cpu_high_loss.empty:
            print(f"   üî¥ GOULOT NON-CPU: Charge CPU faible mais pertes √©lev√©es ‚Üí Probl√®me r√©seau/I/O")
        
        if not high_cpu_low_throughput.empty:
            print(f"   üî¥ GOULOT CPU: Charge CPU √©lev√©e avec faible d√©bit ‚Üí Optimisation algorithmes n√©cessaire")
        
        # Analyse de la scalabilit√©
        if len(df) > 1:
            first_eff = df.iloc[0]['throughput_efficiency_pct']
            last_eff = df.iloc[-1]['throughput_efficiency_pct']
            scalability_trend = last_eff - first_eff
            
            if scalability_trend < -20:
                print(f"   üìâ SCALABILIT√â M√âDIOCRE: D√©gradation de {abs(scalability_trend):.1f}% entre d√©bits min/max")
            elif scalability_trend > 5:
                print(f"   üìà BONNE SCALABILIT√â: Am√©lioration de {scalability_trend:.1f}% avec la charge")
            else:
                print(f"   üìä SCALABILIT√â STABLE: Variation de {scalability_trend:.1f}% entre d√©bits")
        
        print(f"\nüîç ANALYSE D√âTAILL√âE PAR D√âBIT:")
        for _, row in df.iterrows():
            # √âvaluation de la performance globale
            score_debit = min(row['throughput_efficiency_pct'], 100)
            score_cpu = min((row['packets_per_cpu_sec'] / 1000) * 10, 100)  # Normalis√©
            score_detection = min(row['detection_efficiency_pct'], 100)
            score_global = (score_debit + score_cpu + score_detection) / 3
            
            # Ic√¥ne de performance
            if score_global >= 80:
                perf_icon = "üü¢ EXCELLENT"
            elif score_global >= 60:
                perf_icon = "üü° CORRECT"
            elif score_global >= 40:
                perf_icon = "üü† PASSABLE"
            else:
                perf_icon = "üî¥ CRITIQUE"
            
            print(f"\n   üìå {int(row['rate_pps'])} pps - {perf_icon} (Score: {score_global:.1f}/100)")
            print(f"      ‚îú‚îÄ üìä Performance: {row['debit_avg_pps']:.1f} pps mesur√©s ({row['throughput_efficiency_pct']:.1f}% efficacit√©)")
            print(f"      ‚îú‚îÄ ‚ùå Pertes: {row['packet_loss_pct']:.1f}% de paquets perdus")
            print(f"      ‚îú‚îÄ üïê Latence: {row['latency_avg_usecs']:.3f} ¬µs (max: {row['latency_max_usecs']:.0f} ¬µs)")
            print(f"      ‚îú‚îÄ ‚ö° CPU: {row['cpu_load_pct']:.1f}% charge ({row['cpu_time_per_packet_usec']:.2f} ¬µs/pkt)")
            print(f"      ‚îú‚îÄ üöÄ Efficacit√© CPU: {row['packets_per_cpu_sec']:.0f} pkt/sec CPU")
            print(f"      ‚îú‚îÄ üîç D√©tection: {row['detection_analyzed']:,} paquets ({row['detection_efficiency_pct']:.1f}%)")
            print(f"      ‚îú‚îÄ üåä Stream: {row['stream_flows']} flux ({row['flows_per_sec']:.1f} flux/sec)")
            print(f"      ‚îî‚îÄ üì¶ Paquets/flux: {row['packets_per_flow']:.1f}")
        
        print(f"\nüéØ RECOMMANDATIONS D'OPTIMISATION:")
        
        # Recommandations bas√©es sur l'analyse
        avg_cpu_load = df['cpu_load_pct'].mean()
        avg_loss = df['packet_loss_pct'].mean()
        avg_efficiency = df['throughput_efficiency_pct'].mean()
        
        if avg_cpu_load < 25 and avg_loss > 30:
            print(f"   üí° PRIORIT√â 1: Optimiser le r√©seau/I/O (CPU sous-utilis√©: {avg_cpu_load:.1f}%)")
        elif avg_cpu_load > 70:
            print(f"   üí° PRIORIT√â 1: Optimiser les algorithmes CPU (charge √©lev√©e: {avg_cpu_load:.1f}%)")
        
        if avg_efficiency < 50:
            print(f"   üí° PRIORIT√â 2: Configuration Snort sous-optimale (efficacit√©: {avg_efficiency:.1f}%)")
        
        # D√©bit optimal recommand√©
        best_efficiency_rate = df.loc[df['throughput_efficiency_pct'].idxmax(), 'rate_pps']
        print(f"   üí° RECOMMANDATION: D√©bit optimal pour production = {best_efficiency_rate:.0f} pps")
        
        # Capacit√© maximale estim√©e
        max_theoretical_pps = df['packets_per_cpu_sec'].max() * (df['cpu_load_pct'].min() / 100)
        if max_theoretical_pps > 0:
            print(f"   üí° ESTIMATION: Capacit√© th√©orique maximale ‚âà {max_theoretical_pps:.0f} pps")
        
        print(f"\nüìà M√âTRIQUES TECHNIQUES AVANC√âES:")
        print(f"   üîß Ratio User/System CPU moyen: {df['cpu_user_sys_ratio'].mean():.2f}")
        print(f"   üîß Efficacit√© CPU/Runtime moyenne: {df['cpu_efficiency_ratio'].mean():.2f}")
        print(f"   üîß Paquets par flux moyen: {df['packets_per_flow'].mean():.1f}")
        print(f"   üîß Flux cr√©√©s par seconde moyen: {df['flows_per_sec'].mean():.1f}")
        
        print(f"\nüìã R√âSUM√â EX√âCUTIF:")
        if avg_efficiency > 80:
            verdict = "üü¢ PERFORMANCE EXCELLENTE"
            recommendation = "Configuration pr√™te pour production"
        elif avg_efficiency > 60:
            verdict = "üü° PERFORMANCE CORRECTE"
            recommendation = "Optimisations mineures recommand√©es"
        elif avg_efficiency > 40:
            verdict = "üü† PERFORMANCE PASSABLE"
            recommendation = "Optimisations importantes n√©cessaires"
        else:
            verdict = "üî¥ PERFORMANCE CRITIQUE"
            recommendation = "R√©vision compl√®te de la configuration requise"
        
        print(f"   üéñÔ∏è  VERDICT: {verdict}")
        print(f"   üéñÔ∏è  EFFICACIT√â GLOBALE: {avg_efficiency:.1f}%")
        print(f"   üéñÔ∏è  RECOMMANDATION: {recommendation}")
        print(f"   üéñÔ∏è  D√âBIT OPTIMAL: {best_efficiency_rate:.0f} pps")
        
        # Timestamp de l'analyse
        print(f"\nüïê Analyse g√©n√©r√©e le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print(f"üë§ Utilisateur: theTigerFox")
        print("üî•"*100)
    
    def run_ultimate_analysis(self):
        """
        Lance l'analyse ULTIME compl√®te avec tous les histogrammes
        """
        print("üî•üî•üî• LANCEMENT DE L'ANALYSE ULTIME SNORT 3 üî•üî•üî•")
        print("="*80)
        
        # Collecte des donn√©es avec parsing correct
        self.collect_data()
        
        if not self.data:
            print("‚ùå Aucune donn√©e collect√©e. V√©rifiez vos fichiers de r√©sultats.")
            return
        
        print(f"\n‚úÖ Donn√©es collect√©es pour {len(self.data)} configurations de d√©bit")
        
        # G√©n√©ration de TOUS les histogrammes
        print("\nüé® G√©n√©ration des histogrammes ULTIMES...")
        
        try:
            print("   üìä 1/7 - Histogramme comparaison d√©bits...")
            self.create_histogram_debit_comparison()
            
            print("   üìä 2/7 - Histogramme analyse CPU...")
            self.create_histogram_cpu_analysis()
            
            print("   üìä 3/7 - Histogramme ratios Paquets/CPU...")
            self.create_histogram_packets_cpu_ratios()
            
            print("   üìä 4/7 - Histogramme comparaison modules...")
            self.create_histogram_modules_comparison()
            
            print("   üìä 5/7 - Histogramme analyse protocoles...")
            self.create_histogram_protocol_analysis()
            
            print("   üìä 6/7 - Histogramme r√©sum√© performance...")
            self.create_histogram_performance_summary()
            
            print("   üìä 7/7 - Histogramme ULTIME comparaison...")
            self.create_ultimate_comparison_histogram()
            
            print(f"\nüéâ 7 HISTOGRAMMES G√âN√âR√âS avec succ√®s dans {self.figures_dir}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de la g√©n√©ration d'un histogramme: {e}")
            import traceback
            traceback.print_exc()
        
        # Cr√©ation du DataFrame r√©sum√© complet
        print("\nüìã Cr√©ation du r√©sum√© ULTRA-D√âTAILL√â...")
        df = self.create_summary_dataframe()
        
        # Sauvegarde du CSV ultra-complet
        csv_path = self.results_dir / 'summary_ultimate.csv'
        df.to_csv(csv_path, index=False)
        print(f"üíæ R√©sum√© ULTIME sauvegard√©: {csv_path}")
        
        # Affichage du DataFrame
        if ACE_TOOLS_AVAILABLE:
            try:
                ace_tools.display_dataframe_to_user(
                    name="üî• ANALYSE ULTIME SNORT 3 - DONN√âES COMPL√àTES üî•",
                    dataframe=df,
                    description="Analyse exhaustive avec TOUTES les m√©triques, ratios et comparaisons"
                )
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur ace_tools: {e}")
                print("\nüìä DATAFRAME R√âSUM√â ULTIME:")
                # Affichage des colonnes les plus importantes
                key_columns = ['rate_pps', 'debit_avg_pps', 'throughput_efficiency_pct', 
                             'packet_loss_pct', 'cpu_load_pct', 'packets_per_cpu_sec',
                             'detection_efficiency_pct']
                print(df[key_columns].to_string(index=False))
        else:
            print("\nüìä DATAFRAME R√âSUM√â ULTIME (colonnes cl√©s):")
            key_columns = ['rate_pps', 'debit_avg_pps', 'throughput_efficiency_pct', 
                         'packet_loss_pct', 'cpu_load_pct', 'packets_per_cpu_sec',
                         'detection_efficiency_pct']
            print(df[key_columns].to_string(index=False))
        
        # Statistiques r√©sum√©es ULTRA-D√âTAILL√âES
        self.print_ultimate_summary_statistics(df)
        
        print(f"\nüéäüéäüéä ANALYSE ULTIME TERMIN√âE AVEC SUCC√àS ! üéäüéäüéä")
        print(f"üìÅ FICHIERS G√âN√âR√âS dans {self.results_dir}:")
        print(f"   üé® 7 histogrammes PNG dans {self.figures_dir}/")
        print(f"   üìÑ summary_ultimate.csv avec TOUTES les m√©triques")
        print(f"   üìä Analyse comparative EXHAUSTIVE affich√©e ci-dessus")
        print(f"   üî• Recommandations d'optimisation personnalis√©es")
        print("\n" + "üöÄ"*50 + " MISSION ACCOMPLIE " + "üöÄ"*50)

def main():
    """
    Fonction principale avec gestion d'arguments am√©lior√©e
    """
    if len(sys.argv) == 1:
        # Si aucun argument, utiliser le r√©pertoire courant
        results_dir = "."
        print("‚ÑπÔ∏è  Aucun r√©pertoire sp√©cifi√©, utilisation du r√©pertoire courant")
    elif len(sys.argv) == 2:
        results_dir = sys.argv[1]
    else:
        print("Usage: python3 analyze_snort_results_ultimate.py [/chemin/vers/results]")
        print("Exemple: python3 analyze_snort_results_ultimate.py .")
        print("Exemple: python3 analyze_snort_results_ultimate.py /path/to/results")
        sys.exit(1)
    
    if not os.path.exists(results_dir):
        print(f"‚ùå Le r√©pertoire {results_dir} n'existe pas")
        sys.exit(1)
    
    print(f"üéØ Analyse des r√©sultats dans: {os.path.abspath(results_dir)}")
    
    analyzer = SnortUltimateAnalyzer(results_dir)
    analyzer.run_ultimate_analysis()

if __name__ == "__main__":
    main()